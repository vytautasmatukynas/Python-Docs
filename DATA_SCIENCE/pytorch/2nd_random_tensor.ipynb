{
 "cells": [
  {
   "cell_type": "code",
   "id": "61e3e6f1f9ea371b",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.716913Z",
     "start_time": "2024-08-04T13:32:37.713142Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Random Tensors\n",
    "\n",
    "Random tensors aid in model initialization, data augmentation, and training efficiency. The model learns patterns from diverse samples during training.\n",
    "\n",
    "LT -> Atsitiktiniai tenzoriai padeda modelio inicializavimui, duomenų praplėtimui ir mokymo efektyvumui. Modelis mokosi atpažinti raštus iš įvairių pavyzdžių mokymo metu.\n",
    "\n",
    "Example: Training a robot to recognize chickens involves showing it varied images of chickens and other animals. Random tensors represent these varied images, helping the model learn and improve its recognition skills.\n",
    "\n",
    "LT -> Pavyzdys: Mokant robotą atpažinti vištas, jam rodomos įvairios vištų ir kitų gyvūnų nuotraukos. Atsitiktiniai tenzoriai atspindi šias įvairias nuotraukas, padėdami modeliui tobulinti atpažinimo įgūdžius."
   ],
   "id": "fd148ad16abb79aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.749438Z",
     "start_time": "2024-08-04T13:32:37.741924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random tensor\n",
    "RANDOM_TENSOR = torch.rand(2, 2, 2)\n",
    "RANDOM_TENSOR"
   ],
   "id": "f47655d12b13af93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0204, 0.6226],\n",
       "         [0.0089, 0.6280]],\n",
       "\n",
       "        [[0.4461, 0.2286],\n",
       "         [0.0664, 0.6952]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.761191Z",
     "start_time": "2024-08-04T13:32:37.753451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random tensor dimensions\n",
    "RANDOM_TENSOR.ndim"
   ],
   "id": "cf9c55d98bd5285b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.774665Z",
     "start_time": "2024-08-04T13:32:37.763199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Random tensor with similar shape to an image tensor\n",
    "# PyTorch uses the channel-first format ((C, H, W))\n",
    "# PyTorch tensor for image -> size=(colour channels (R, G, B), height, width)\n",
    "RANDOM_IMG_TENSOR = torch.rand(size=(3, 128, 128))  # colour channels (R, G, B), height, width\n",
    "RANDOM_IMG_TENSOR"
   ],
   "id": "206e9014f311c8b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8097, 0.3145, 0.5737,  ..., 0.2311, 0.5125, 0.8097],\n",
       "         [0.6846, 0.9890, 0.8954,  ..., 0.5940, 0.5929, 0.9049],\n",
       "         [0.4109, 0.3563, 0.1404,  ..., 0.4762, 0.7305, 0.7622],\n",
       "         ...,\n",
       "         [0.4371, 0.9126, 0.4181,  ..., 0.6800, 0.7452, 0.7573],\n",
       "         [0.6488, 0.8657, 0.2467,  ..., 0.9875, 0.6259, 0.6983],\n",
       "         [0.8706, 0.5160, 0.8822,  ..., 0.4299, 0.8750, 0.9695]],\n",
       "\n",
       "        [[0.7610, 0.8295, 0.0884,  ..., 0.2374, 0.7499, 0.9922],\n",
       "         [0.5217, 0.5753, 0.8724,  ..., 0.6318, 0.6163, 0.3583],\n",
       "         [0.1771, 0.3003, 0.7198,  ..., 0.4518, 0.9411, 0.9114],\n",
       "         ...,\n",
       "         [0.4660, 0.1060, 0.3641,  ..., 0.8032, 0.8722, 0.4924],\n",
       "         [0.0083, 0.0124, 0.2258,  ..., 0.1334, 0.8430, 0.6218],\n",
       "         [0.2683, 0.7962, 0.2847,  ..., 0.0961, 0.2561, 0.3902]],\n",
       "\n",
       "        [[0.8870, 0.0786, 0.2439,  ..., 0.2012, 0.3275, 0.9437],\n",
       "         [0.6591, 0.7582, 0.9895,  ..., 0.1045, 0.9343, 0.2067],\n",
       "         [0.7313, 0.6296, 0.0034,  ..., 0.4999, 0.5013, 0.0840],\n",
       "         ...,\n",
       "         [0.4962, 0.3059, 0.2709,  ..., 0.8347, 0.4642, 0.8200],\n",
       "         [0.5917, 0.3844, 0.1757,  ..., 0.9568, 0.5392, 0.8784],\n",
       "         [0.1514, 0.1343, 0.4760,  ..., 0.8468, 0.2578, 0.5534]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.782579Z",
     "start_time": "2024-08-04T13:32:37.776690Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_IMG_TENSOR.shape, RANDOM_IMG_TENSOR.ndim",
   "id": "6d4745e88274c363",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 128, 128]), 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.792219Z",
     "start_time": "2024-08-04T13:32:37.783591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create tensor of 0\n",
    "ZERO = torch.zeros(size=(2, 2, 2))\n",
    "ZERO"
   ],
   "id": "688cbfc28fbc0c90",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.801969Z",
     "start_time": "2024-08-04T13:32:37.795230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create tensor of 1\n",
    "ONES = torch.ones(size=(2, 2, 2))\n",
    "ONES"
   ],
   "id": "bee05b400bd21a56",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1.],\n",
       "         [1., 1.]],\n",
       "\n",
       "        [[1., 1.],\n",
       "         [1., 1.]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T13:32:37.810186Z",
     "start_time": "2024-08-04T13:32:37.803979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tensor data types\n",
    "RANDOM_TENSOR.dtype, RANDOM_IMG_TENSOR.dtype, ZERO.dtype, ONES.dtype"
   ],
   "id": "b9c973c6075e96aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.float32, torch.float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
